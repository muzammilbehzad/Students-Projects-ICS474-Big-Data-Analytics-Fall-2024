{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f3ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60cb6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2019-01-01 00:00:18  2703186189652095   \n",
      "1           1   2019-01-01 00:00:44      630423337322   \n",
      "2           2   2019-01-01 00:00:51    38859492057661   \n",
      "3           3   2019-01-01 00:01:16  3534093764340240   \n",
      "4           4   2019-01-01 00:03:06   375534208663984   \n",
      "\n",
      "                             merchant       category     amt      first  \\\n",
      "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
      "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
      "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
      "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
      "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
      "\n",
      "      last gender                        street  ...      long city_pop  \\\n",
      "0    Banks      F                561 Perry Cove  ...  -81.1781     3495   \n",
      "1     Gill      F  43039 Riley Greens Suite 393  ... -118.2105      149   \n",
      "2  Sanchez      M      594 White Dale Suite 530  ... -112.2620     4154   \n",
      "3    White      M   9443 Cynthia Court Apt. 038  ... -112.1138     1939   \n",
      "4   Garcia      M              408 Bradley Rest  ...  -79.4629       99   \n",
      "\n",
      "                                 job         dob  \\\n",
      "0          Psychologist, counselling  1988-03-09   \n",
      "1  Special educational needs teacher  1978-06-21   \n",
      "2        Nature conservation officer  1962-01-19   \n",
      "3                    Patent attorney  1967-01-12   \n",
      "4     Dance movement psychotherapist  1986-03-28   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
      "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
      "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
      "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
      "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
      "\n",
      "  is_fraud  merch_zipcode  \n",
      "0        0        28705.0  \n",
      "1        0            NaN  \n",
      "2        0        83236.0  \n",
      "3        0            NaN  \n",
      "4        0        22844.0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = pd.read_csv(\"credit_card_transactions.csv\")\n",
    "\n",
    "is_fraud = X[[\"is_fraud\"]]\n",
    "\n",
    "is_fraud.to_csv(\"is_fraud.csv\", index=False)\n",
    "#1296675 rows x 24 columns\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73df0d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted times saved to updated_dataset_2.csv\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "time_column = 'trans_date_trans_time'\n",
    "local_time_zone = 'Asia/Riyadh' \n",
    "def convert_to_utc(local_time_str):\n",
    "    local_tz = pytz.timezone(local_time_zone)\n",
    "    # Parse the string into a datetime object\n",
    "    local_time = datetime.strptime(local_time_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "    # Localize and convert to UTC\n",
    "    localized_time = local_tz.localize(local_time)\n",
    "    utc_time = localized_time.astimezone(pytz.utc)\n",
    "    return utc_time\n",
    "\n",
    "# Apply the function to the dataset\n",
    "X['utc_time'] = X['trans_date_trans_time'].apply(convert_to_utc)\n",
    "X = X.drop(columns=['trans_date_trans_time'])\n",
    "X = X.drop(columns=['is_fraud'])\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_file = \"updated_dataset_2.csv\"\n",
    "X.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Converted times saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9354a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv(\"is_fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef31f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"updated_dataset_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34cd8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "columns_to_drop = ['Unnamed: 0','street', 'first', 'last','merch_zipcode']\n",
    "X = X.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cd23650",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['merchant', 'category', 'gender', 'city',\n",
    "                       'state', 'job']\n",
    "label_encoders = {}  # Store encoders for potential inverse transformation\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12b44d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "X['dob'] = pd.to_datetime(X['dob'], errors='coerce')  # Converts 'dob' to datetime\n",
    "X['utc_time'] = pd.to_datetime(X['utc_time'], errors='coerce')  # Converts 'utc_time' to datetime\n",
    "\n",
    "# Extract features from 'dob'\n",
    "X['dob_year'] = X['dob'].dt.year\n",
    "X['dob_month'] = X['dob'].dt.month\n",
    "X['dob_day'] = X['dob'].dt.day\n",
    "\n",
    "# Extract features from 'utc_time'\n",
    "X['utc_hour'] = X['utc_time'].dt.hour\n",
    "\n",
    "# Handle missing values (if necessary)\n",
    "X['dob'].fillna(pd.Timestamp('2000-01-01'), inplace=True)  # Fill missing 'dob' with default date\n",
    "X['utc_time'].fillna(method='ffill', inplace=True)  # Fill missing 'utc_time' with forward fill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58b4ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [ 'dob', 'utc_time']\n",
    "X = X.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2379f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [ 'trans_num']\n",
    "X = X.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16d14348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the Data (important for KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3132e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "X_train_selected = X_train\n",
    "X_test_selected = X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b88acf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train_selected: 0\n",
      "NaN values in X_test_selected: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for NaN values in the training set\n",
    "print(\"NaN values in X_train_selected:\", np.isnan(X_train_selected).sum())\n",
    "\n",
    "# Check for NaN values in the testing set\n",
    "print(\"NaN values in X_test_selected:\", np.isnan(X_test_selected).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e26b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [ 'merch_zipcode']\n",
    "X = X.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee9723d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"updated_dataset_3.csv\"\n",
    "X.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ad16796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.keys of          is_fraud\n",
      "0               0\n",
      "1               0\n",
      "2               0\n",
      "3               0\n",
      "4               0\n",
      "...           ...\n",
      "1296670         0\n",
      "1296671         0\n",
      "1296672         0\n",
      "1296673         0\n",
      "1296674         0\n",
      "\n",
      "[1296675 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(Y.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0eab58d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-d2d07b47a2fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Reshape y_train and y_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convert to NumPy array and flatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# Train KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Reshape y_train and y_test\n",
    "y_train = y_train.values.ravel()  # Convert to NumPy array and flatten\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "knn.fit(X_train_selected, y_train)\n",
    "print(\"Test Accuracy:\", knn.score(X_test_selected, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1a364ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1296675, 21)\n",
      "Shape of Y: (1296675, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "055e84dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.read_csv(\"updated_dataset_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e48d07a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (1296675, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Y:\", Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bbaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6bcd48d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993572020745368\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    257815\n",
      "           1       0.00      0.00      0.00      1520\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.50      0.50      0.50    259335\n",
      "weighted avg       0.99      0.99      0.99    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "eb3580b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming X (features) and y (labels)\n",
    "X = X.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "Y =Y.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "477e5011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is_fraud\n",
      "0               0\n",
      "1               0\n",
      "2               0\n",
      "3               0\n",
      "4               0\n",
      "...           ...\n",
      "1296670         0\n",
      "1296671         0\n",
      "1296672         0\n",
      "1296673         0\n",
      "1296674         0\n",
      "\n",
      "[1296675 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e1295ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is_fraud\n",
      "0               0\n",
      "1               0\n",
      "2               0\n",
      "3               0\n",
      "4               0\n",
      "...           ...\n",
      "1296670         0\n",
      "1296671         0\n",
      "1296672         0\n",
      "1296673         0\n",
      "1296674         0\n",
      "\n",
      "[1296675 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "N = pd.read_csv(\"is_fraud.csv\")\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca0f8138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (778005, 21) (778005, 1)\n",
      "Validation Set: (259335, 21) (259335, 1)\n",
      "Test Set: (259335, 21) (259335, 1)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the dataset into Train, Validation, and Test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.4, random_state=42)  # 60% train, 40% temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 20% val, 20% test\n",
    "\n",
    "print(\"Training Set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation Set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test Set:\", X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9ee71044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42,\n",
       "                   solver='saga', tol=100000.0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Train the Logistic Regression model\n",
    "clf = LogisticRegression(\n",
    "    random_state=42, \n",
    "    solver='saga',  \n",
    "    penalty='l2',   \n",
    "    max_iter=1000,  \n",
    "    tol=1e5,       \n",
    "    C=1.0,        \n",
    "    class_weight='balanced'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6b4cefbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9166252144909094\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    257840\n",
      "           1       0.05      0.74      0.09      1495\n",
      "\n",
      "    accuracy                           0.92    259335\n",
      "   macro avg       0.52      0.83      0.52    259335\n",
      "weighted avg       0.99      0.92      0.95    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Validate on the validation set\n",
    "y_val_pred = clf.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Validation Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3f702214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.917454258006054\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    257866\n",
      "           1       0.05      0.72      0.09      1469\n",
      "\n",
      "    accuracy                           0.92    259335\n",
      "   macro avg       0.52      0.82      0.52    259335\n",
      "weighted avg       0.99      0.92      0.95    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Test on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "52247ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(clf, 'logistic_regression_model.pkl')\n",
    "\n",
    "# Save the scaler as well to preprocess new data consistently\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f45c7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('logistic_regression_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4312388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Z = pd.read_csv(\"updated_dataset_4.csv\")\n",
    "# Step 2: Take 10 rows from the dataset (e.g., the first 10 rows or a random sample)\n",
    "X_new = Z.iloc[:10]  # First 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6a57584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   merchant  category     amt  gender  city  state    zip      lat      long  \\\n",
      "0       514         8    4.97       0   526     27  28654  36.0788  -81.1781   \n",
      "1       241         4  107.23       0   612     47  99160  48.8878 -118.2105   \n",
      "2       390         0  220.11       1   468     13  83252  42.1808 -112.2620   \n",
      "3       360         2   45.00       1    84     26  59632  46.2306 -112.1138   \n",
      "4       297         9   41.96       1   216     45  24433  38.4207  -79.4629   \n",
      "\n",
      "   city_pop  ...   unix_time  merch_lat  merch_long  dob_year  dob_month  \\\n",
      "0      3495  ...  1325376018  36.011293  -82.048315      1988          3   \n",
      "1       149  ...  1325376044  49.159047 -118.186462      1978          6   \n",
      "2      4154  ...  1325376051  43.150704 -112.154481      1962          1   \n",
      "3      1939  ...  1325376076  47.034331 -112.561071      1967          1   \n",
      "4        99  ...  1325376186  38.674999  -78.632459      1986          3   \n",
      "\n",
      "   dob_day  utc_hour  utc_minute  utc_second  service_provider  \n",
      "0        9        21           0          18                 3  \n",
      "1       21        21           0          44                 4  \n",
      "2       19        21           0          51                 4  \n",
      "3       12        21           1          16                 2  \n",
      "4       28        21           3           6                 0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bbe14906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_new_scaled = scaler.transform(X_new)  # Preprocess the new data\n",
    "\n",
    "y_new_pred = clf.predict(X_new_scaled)\n",
    "\n",
    "y_new_prob = clf.predict_proba(X_new_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "16e75cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 1 1 0 1 0 1 0 1]\n",
      "Prediction Probabilities: [[0.71131796 0.28868204]\n",
      " [0.39837557 0.60162443]\n",
      " [0.17688079 0.82311921]\n",
      " [0.46653622 0.53346378]\n",
      " [0.72507633 0.27492367]\n",
      " [0.28966989 0.71033011]\n",
      " [0.56143298 0.43856702]\n",
      " [0.39873486 0.60126514]\n",
      " [0.64526515 0.35473485]\n",
      " [0.2208352  0.7791648 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\", y_new_pred)\n",
    "\n",
    "# (Optional) Step 5: Predict probabilities\n",
    "y_new_prob = clf.predict_proba(X_new_scaled)\n",
    "print(\"Prediction Probabilities:\", y_new_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6fc45d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc987870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of X: ['cc_num', 'merchant', 'category', 'amt', 'gender', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'unix_time', 'merch_lat', 'merch_long', 'dob_year', 'dob_month', 'dob_day', 'utc_hour', 'utc_minute', 'utc_second']\n"
     ]
    }
   ],
   "source": [
    "keys_list = list(X.columns)\n",
    "print(\"Keys of X:\", keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_keys: ['cc_num', 'merchant', 'category', 'amt', 'gender',\n",
    "    'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job',\n",
    "    'unix_time', 'merch_lat', 'merch_long', 'dob_year', \n",
    "    'dob_month', 'dob_day', 'utc_hour', 'utc_minute',\n",
    "    'utc_second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae0c330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service_provider(cc_number):\n",
    "    cc_number = str(cc_number)  # Ensure the credit card number is a string\n",
    "    if cc_number.startswith('4'):\n",
    "        return 'Visa'\n",
    "    elif 51 <= int(cc_number[:2]) <= 55 or 2221 <= int(cc_number[:4]) <= 2720:\n",
    "        return 'MasterCard'\n",
    "    elif cc_number.startswith('34') or cc_number.startswith('37'):\n",
    "        return 'American Express'\n",
    "    elif cc_number.startswith('6011') or cc_number.startswith('65') or \\\n",
    "         (644 <= int(cc_number[:3]) <= 649) or (622126 <= int(cc_number[:6]) <= 622925):\n",
    "        return 'Discover'\n",
    "    elif 3528 <= int(cc_number[:4]) <= 3589:\n",
    "        return 'JCB'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c61849f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['service_provider'] = X['cc_num'].apply(get_service_provider)\n",
    "\n",
    "columns_to_drop = [ 'cc_num']\n",
    "X = X.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "label_encoders = {}  # Store encoders for potential inverse transformation\n",
    "\n",
    "label_encoders['service_provider'] = LabelEncoder()\n",
    "X['service_provider'] = label_encoders['service_provider'].fit_transform(X['service_provider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae7ac641",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"updated_dataset_4.csv\"\n",
    "X.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'updated_dataset.csv'  # Replace with your dataset path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define features (X) and target (Y)\n",
    "X = data.drop(columns=['label_column'])  # Replace 'label_column' with your target column\n",
    "Y = data['label_column']  # Replace 'label_column' with your target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75b97d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cc_num',\n",
       " 'merchant',\n",
       " 'category',\n",
       " 'amt',\n",
       " 'gender',\n",
       " 'city',\n",
       " 'state',\n",
       " 'zip',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'city_pop',\n",
       " 'job',\n",
       " 'unix_time',\n",
       " 'merch_lat',\n",
       " 'merch_long',\n",
       " 'dob_year',\n",
       " 'dob_month',\n",
       " 'dob_day',\n",
       " 'utc_hour',\n",
       " 'utc_minute',\n",
       " 'utc_second']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6c85943",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()  # Convert to NumPy array and flatten\n",
    "y_test = y_test.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6858be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy Forward Selection\n",
    "selected_features = []\n",
    "remaining_features = list(X_train.columns)\n",
    "best_accuracy = 0\n",
    "\n",
    "while len(selected_features) < 5 or x==25:\n",
    "    x=+1\n",
    "    best_feature = None\n",
    "    for feature in remaining_features:\n",
    "        # Test current feature with selected features\n",
    "        current_features = selected_features + [feature]\n",
    "        X_train_subset = X_train[current_features]\n",
    "        X_test_subset = X_test[current_features]\n",
    "\n",
    "        # Scale the data\n",
    "        X_train_subset_scaled = scaler.fit_transform(X_train_subset)\n",
    "        X_test_subset_scaled = scaler.transform(X_test_subset)\n",
    "\n",
    "        # Train Logistic Regression\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        model.fit(X_train_subset_scaled, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test_subset_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Check if this is the best feature to add\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_feature = feature\n",
    "\n",
    "    # Add the best feature to the selected list\n",
    "    if best_feature:\n",
    "        selected_features.append(best_feature)\n",
    "        remaining_features.remove(best_feature)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3969cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0 trans_date_trans_time               cc_num  \\\n",
      "0                 0   2019-01-01 00:00:18     2703186189652095   \n",
      "1                 1   2019-01-01 00:00:44         630423337322   \n",
      "2                 2   2019-01-01 00:00:51       38859492057661   \n",
      "3                 3   2019-01-01 00:01:16     3534093764340240   \n",
      "4                 4   2019-01-01 00:03:06      375534208663984   \n",
      "...             ...                   ...                  ...   \n",
      "1296670     1296670   2020-06-21 12:12:08       30263540414123   \n",
      "1296671     1296671   2020-06-21 12:12:19     6011149206456997   \n",
      "1296672     1296672   2020-06-21 12:12:32     3514865930894695   \n",
      "1296673     1296673   2020-06-21 12:13:36     2720012583106919   \n",
      "1296674     1296674   2020-06-21 12:13:37  4292902571056973207   \n",
      "\n",
      "                                    merchant       category     amt  \\\n",
      "0                 fraud_Rippin, Kub and Mann       misc_net    4.97   \n",
      "1            fraud_Heller, Gutmann and Zieme    grocery_pos  107.23   \n",
      "2                       fraud_Lind-Buckridge  entertainment  220.11   \n",
      "3         fraud_Kutch, Hermiston and Farrell  gas_transport   45.00   \n",
      "4                        fraud_Keeling-Crist       misc_pos   41.96   \n",
      "...                                      ...            ...     ...   \n",
      "1296670                    fraud_Reichel Inc  entertainment   15.56   \n",
      "1296671             fraud_Abernathy and Sons    food_dining   51.70   \n",
      "1296672                 fraud_Stiedemann Ltd    food_dining  105.93   \n",
      "1296673  fraud_Reinger, Weissnat and Strosin    food_dining   74.90   \n",
      "1296674  fraud_Langosh, Wintheiser and Hyatt    food_dining    4.30   \n",
      "\n",
      "               first       last gender                         street  ...  \\\n",
      "0           Jennifer      Banks      F                 561 Perry Cove  ...   \n",
      "1          Stephanie       Gill      F   43039 Riley Greens Suite 393  ...   \n",
      "2             Edward    Sanchez      M       594 White Dale Suite 530  ...   \n",
      "3             Jeremy      White      M    9443 Cynthia Court Apt. 038  ...   \n",
      "4              Tyler     Garcia      M               408 Bradley Rest  ...   \n",
      "...              ...        ...    ...                            ...  ...   \n",
      "1296670         Erik  Patterson      M       162 Jessica Row Apt. 072  ...   \n",
      "1296671      Jeffrey      White      M  8617 Holmes Terrace Suite 651  ...   \n",
      "1296672  Christopher  Castaneda      M     1632 Cohen Drive Suite 639  ...   \n",
      "1296673       Joseph     Murray      M           42933 Ryan Underpass  ...   \n",
      "1296674      Jeffrey      Smith      M           135 Joseph Mountains  ...   \n",
      "\n",
      "             long city_pop                                job         dob  \\\n",
      "0        -81.1781     3495          Psychologist, counselling  1988-03-09   \n",
      "1       -118.2105      149  Special educational needs teacher  1978-06-21   \n",
      "2       -112.2620     4154        Nature conservation officer  1962-01-19   \n",
      "3       -112.1138     1939                    Patent attorney  1967-01-12   \n",
      "4        -79.4629       99     Dance movement psychotherapist  1986-03-28   \n",
      "...           ...      ...                                ...         ...   \n",
      "1296670 -112.4777      258                       Geoscientist  1961-11-24   \n",
      "1296671  -77.5101      100   Production assistant, television  1979-12-11   \n",
      "1296672 -105.8189      899                    Naval architect  1967-08-30   \n",
      "1296673 -102.5411     1126              Volunteer coordinator  1980-08-18   \n",
      "1296674 -113.8748      218           Therapist, horticultural  1995-08-16   \n",
      "\n",
      "                                trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0        0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
      "1        1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
      "2        a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
      "3        6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
      "4        a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
      "...                                   ...         ...        ...         ...   \n",
      "1296670  440b587732da4dc1a6395aba5fb41669  1371816728  36.841266 -111.690765   \n",
      "1296671  278000d2e0d2277d1de2f890067dcc0a  1371816739  38.906881  -78.246528   \n",
      "1296672  483f52fe67fabef353d552c1e662974c  1371816752  33.619513 -105.130529   \n",
      "1296673  d667cdcbadaaed3da3f4020e83591c83  1371816816  42.788940 -103.241160   \n",
      "1296674  8f7c8e4ab7f25875d753b422917c98c9  1371816817  46.565983 -114.186110   \n",
      "\n",
      "        is_fraud  merch_zipcode  \n",
      "0              0        28705.0  \n",
      "1              0            NaN  \n",
      "2              0        83236.0  \n",
      "3              0            NaN  \n",
      "4              0        22844.0  \n",
      "...          ...            ...  \n",
      "1296670        0            NaN  \n",
      "1296671        0        22630.0  \n",
      "1296672        0        88351.0  \n",
      "1296673        0        69367.0  \n",
      "1296674        0        59870.0  \n",
      "\n",
      "[1296675 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('credit_card_transactions.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c47cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
